{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1AMJYIlsIVlJNCb0abTYMXofJ44oljKDN","authorship_tag":"ABX9TyMuBFcEsvUVSsf+Qd1e82Oz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J427tRNHn6SC","executionInfo":{"status":"ok","timestamp":1698941492018,"user_tz":-330,"elapsed":6825,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"7733e973-68d4-4bf9-a076-95983bc5fb8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","source":["import os\n","import time\n","import shutil\n","import pathlib\n","import itertools\n","\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n","from tensorflow.keras import regularizers\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print ('modules loaded')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hD0rSSzzbze","executionInfo":{"status":"ok","timestamp":1698941510286,"user_tz":-330,"elapsed":5687,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"ae6282b2-5f09-4ae5-8dfa-a1f1e4782d63"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["modules loaded\n"]}]},{"cell_type":"code","source":["def define_paths(data_dir):\n","    filepaths = []\n","    labels = []\n","\n","    folds = os.listdir(data_dir)\n","    for fold in folds:\n","        foldpath = os.path.join(data_dir, fold)\n","        filelist = os.listdir(foldpath)\n","        for file in filelist:\n","            fpath = os.path.join(foldpath, file)\n","            filepaths.append(fpath)\n","            labels.append(fold)\n","\n","    return filepaths, labels\n","\n","    def define_df(files, classes):\n","       Fseries = pd.Series(files, name= 'filepaths')\n","    Lseries = pd.Series(classes, name='labels')\n","    return pd.concat([Fseries, Lseries], axis= 1)\n","\n","\n","def split_data(data_dir):\n","\n","    files, classes = define_paths(data_dir)\n","    df = define_df(files, classes)\n","    strat = df['labels']\n","    train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n","\n","\n","    strat = dummy_df['labels']\n","    valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)\n","\n","    return train_df, valid_df, test_df"],"metadata":{"id":"eckcsMIIzlKo","executionInfo":{"status":"ok","timestamp":1698941527855,"user_tz":-330,"elapsed":490,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def create_gens (train_df, valid_df, test_df, batch_size):\n","    '''\n","    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n","    Image data generator converts images into tensors. '''\n","\n","\n","\n","    img_size = (224, 224)\n","    channels = 3\n","    color = 'rgb'\n","    img_shape = (img_size[0], img_size[1], channels)\n","\n","\n","    ts_length = len(test_df)\n","    test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","    test_steps = ts_length // test_batch_size\n","    def scalar(img):\n","        return img\n","\n","    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n","    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n","\n","    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","\n","    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= False, batch_size= test_batch_size)\n","\n","    return train_gen, valid_gen, test_gen"],"metadata":{"id":"72zoEoXnzmKA","executionInfo":{"status":"ok","timestamp":1698941543735,"user_tz":-330,"elapsed":497,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def show_images(gen):\n","    '''\n","    This function take the data generator and show sample of the images\n","    '''\n","\n","\n","    g_dict = gen.class_indices\n","    classes = list(g_dict.keys())\n","    images, labels = next(gen)\n","\n","\n","    length = len(labels)\n","    sample = min(length, 25)\n","\n","    plt.figure(figsize= (20, 20))\n","    for i in range(sample):\n","        plt.subplot(5, 5, i + 1)\n","        image = images[i] / 255\n","        plt.imshow(image)\n","        index = np.argmax(labels[i])\n","        class_name = classes[index]\n","        plt.title(class_name, color= 'blue', fontsize= 12)\n","        plt.axis('off')\n","    plt.show()"],"metadata":{"id":"9sZvfweRzqCx","executionInfo":{"status":"ok","timestamp":1698941555984,"user_tz":-330,"elapsed":610,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class MyCallback(keras.callbacks.Callback):\n","    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n","        super(MyCallback, self).__init__()\n","        self.model = model\n","        self.patience = patience # specifies how many epochs without improvement before learning rate is adjusted\n","        self.stop_patience = stop_patience # specifies how many times to adjust lr without improvement to stop training\n","        self.threshold = threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n","        self.factor = factor # factor by which to reduce the learning rate\n","        self.batches = batches # number of training batch to run per epoch\n","        self.epochs = epochs\n","        self.ask_epoch = ask_epoch\n","        self.ask_epoch_initial = ask_epoch # save this value to restore if restarting training\n","\n","        # callback variables\n","        self.count = 0 # how many times lr has been reduced without improvement\n","        self.stop_count = 0\n","        self.best_epoch = 1   # epoch with the lowest loss\n","        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initial learning rate and save it\n","        self.highest_tracc = 0.0 # set highest training accuracy to 0 initially\n","        self.lowest_vloss = np.inf # set lowest validation loss to infinity initially\n","        self.best_weights = self.model.get_weights() # set best weights to model's initial weights\n","        self.initial_weights = self.model.get_weights()   # save initial weights if they have to get restored\n","\n","    # Define a function that will run when train begins\n","    def on_train_begin(self, logs= None):\n","        msg = 'Do you want model asks you to halt the training [y/n] ?'\n","        print(msg)\n","        ans = input('')\n","        if ans in ['Y', 'y']:\n","            self.ask_permission = 1\n","        elif ans in ['N', 'n']:\n","            self.ask_permission = 0\n","\n","        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n","        print(msg)\n","        self.start_time = time.time()\n","\n","\n","    def on_train_end(self, logs= None):\n","        stop_time = time.time()\n","        tr_duration = stop_time - self.start_time\n","        hours = tr_duration // 3600\n","        minutes = (tr_duration - (hours * 3600)) // 60\n","        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n","\n","        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n","        print(msg)\n","\n","        # set the weights of the model to the best weights\n","        self.model.set_weights(self.best_weights)\n","\n","\n","    def on_train_batch_end(self, batch, logs= None):\n","        # get batch accuracy and loss\n","        acc = logs.get('accuracy') * 100\n","        loss = logs.get('loss')\n","\n","        # prints over on the same line to show running batch count\n","        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n","        print(msg, '\\r', end= '')\n","\n","\n","    def on_epoch_begin(self, epoch, logs= None):\n","        self.ep_start = time.time()\n","\n","\n","    # Define method runs on the end of each epoch\n","    def on_epoch_end(self, epoch, logs= None):\n","        ep_end = time.time()\n","        duration = ep_end - self.ep_start\n","\n","        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n","        current_lr = lr\n","        acc = logs.get('accuracy')  # get training accuracy\n","        v_acc = logs.get('val_accuracy')  # get validation accuracy\n","        loss = logs.get('loss')  # get training loss for this epoch\n","        v_loss = logs.get('val_loss')  # get the validation loss for this epoch\n","\n","        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n","            monitor = 'accuracy'\n","            if epoch == 0:\n","                pimprov = 0.0\n","            else:\n","                pimprov = (acc - self.highest_tracc ) * 100 / self.highest_tracc # define improvement of model progres\n","\n","            if acc > self.highest_tracc: # training accuracy improved in the epoch\n","                self.highest_tracc = acc # set new highest training accuracy\n","                self.best_weights = self.model.get_weights() # training accuracy improved so save the weights\n","                self.count = 0 # set count to 0 since training accuracy improved\n","                self.stop_count = 0 # set stop counter to 0\n","                if v_loss < self.lowest_vloss:\n","                    self.lowest_vloss = v_loss\n","                self.best_epoch = epoch + 1  # set the value of best epoch for this epoch\n","\n","            else:\n","                # training accuracy did not improve check if this has happened for patience number of epochs\n","                # if so adjust learning rate\n","                if self.count >= self.patience - 1: # lr should be adjusted\n","                    lr = lr * self.factor # adjust the learning by factor\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n","                    self.count = 0 # reset the count to 0\n","                    self.stop_count = self.stop_count + 1 # count the number of consecutive lr adjustments\n","                    self.count = 0 # reset counter\n","                    if v_loss < self.lowest_vloss:\n","                        self.lowest_vloss = v_loss\n","                else:\n","                    self.count = self.count + 1 # increment patience counter\n","\n","        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n","            monitor = 'val_loss'\n","            if epoch == 0:\n","                pimprov = 0.0\n","\n","            else:\n","                pimprov = (self.lowest_vloss - v_loss ) * 100 / self.lowest_vloss\n","\n","            if v_loss < self.lowest_vloss: # check if the validation loss improved\n","                self.lowest_vloss = v_loss # replace lowest validation loss with new validation loss\n","                self.best_weights = self.model.get_weights() # validation loss improved so save the weights\n","                self.count = 0 # reset count since validation loss improved\n","                self.stop_count = 0\n","                self.best_epoch = epoch + 1 # set the value of the best epoch to this epoch\n","\n","            else: # validation loss did not improve\n","                if self.count >= self.patience - 1: # need to adjust lr\n","                    lr = lr * self.factor # adjust the learning rate\n","                    self.stop_count = self.stop_count + 1 # increment stop counter because lr was adjusted\n","                    self.count = 0 # reset counter\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n","\n","                else:\n","                    self.count = self.count + 1 # increment the patience counter\n","\n","                if acc > self.highest_tracc:\n","                    self.highest_tracc = acc\n","\n","        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n","        print(msg)\n","\n","        if self.stop_count > self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n","            msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n","            print(msg)\n","            self.model.stop_training = True # stop training\n","\n","        else:\n","            if self.ask_epoch != None and self.ask_permission != 0:\n","                if epoch + 1 >= self.ask_epoch:\n","                    msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n","                    print(msg)\n","\n","                    ans = input('')\n","                    if ans == 'H' or ans == 'h':\n","                        msg = f'training has been halted at epoch {epoch + 1} due to user input'\n","                        print(msg)\n","                        self.model.stop_training = True # stop training\n","\n","                    else:\n","                        try:\n","                            ans = int(ans)\n","                            self.ask_epoch += ans\n","                            msg = f' training will continue until epoch {str(self.ask_epoch)}'\n","                            print(msg)\n","                            msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration')\n","                            print(msg)\n","\n","                        except Exception:\n","                            print('Invalid')"],"metadata":{"id":"YSxbxqrEztAV","executionInfo":{"status":"ok","timestamp":1698941569223,"user_tz":-330,"elapsed":601,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import keras"],"metadata":{"id":"nP6l8GMvzwOa","executionInfo":{"status":"ok","timestamp":1698941581329,"user_tz":-330,"elapsed":424,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class MyCallback(keras.callbacks.Callback):\n","    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n","        super(MyCallback, self).__init__()\n","        self.model = model\n","        self.patience = patience\n","        self.stop_patience = stop_patience\n","        self.threshold = threshold\n","        self.factor = factor\n","        self.batches = batches\n","        self.epochs = epochs\n","        self.ask_epoch = ask_epoch\n","        self.ask_epoch_initial = ask_epoch\n","\n","\n","        self.count = 0\n","        self.stop_count = 0\n","        self.best_epoch = 1\n","        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr))\n","        self.highest_tracc = 0.0\n","        self.lowest_vloss = np.inf\n","        self.best_weights = self.model.get_weights()\n","        self.initial_weights = self.model.get_weights()\n","\n","\n","    def on_train_begin(self, logs= None):\n","        msg = 'Do you want model asks you to halt the training [y/n] ?'\n","        print(msg)\n","        ans = input('')\n","        if ans in ['Y', 'y']:\n","            self.ask_permission = 1\n","        elif ans in ['N', 'n']:\n","            self.ask_permission = 0\n","\n","        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n","        print(msg)\n","        self.start_time = time.time()\n","\n","\n","    def on_train_end(self, logs= None):\n","        stop_time = time.time()\n","        tr_duration = stop_time - self.start_time\n","        hours = tr_duration // 3600\n","        minutes = (tr_duration - (hours * 3600)) // 60\n","        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n","\n","        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n","        print(msg)\n","\n","\n","        self.model.set_weights(self.best_weights)\n","\n","\n","    def on_train_batch_end(self, batch, logs= None):\n","\n","        acc = logs.get('accuracy') * 100\n","        loss = logs.get('loss')\n","\n","\n","        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n","        print(msg, '\\r', end= '')\n","\n","\n","    def on_epoch_begin(self, epoch, logs= None):\n","        self.ep_start = time.time()\n","\n","\n","\n","    def on_epoch_end(self, epoch, logs= None):\n","        ep_end = time.time()\n","        duration = ep_end - self.ep_start\n","\n","        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n","        current_lr = lr\n","        acc = logs.get('accuracy')\n","        v_acc = logs.get('val_accuracy')\n","        loss = logs.get('loss')\n","        v_loss = logs.get('val_loss')\n","\n","        if acc < self.threshold:\n","            monitor = 'accuracy'\n","            if epoch == 0:\n","                pimprov = 0.0\n","            else:\n","                pimprov = (acc - self.highest_tracc ) * 100 / self.highest_tracc\n","\n","            if acc > self.highest_tracc:\n","                self.highest_tracc = acc\n","                self.best_weights = self.model.get_weights()\n","                self.count = 0\n","                self.stop_count = 0\n","                if v_loss < self.lowest_vloss:\n","                    self.lowest_vloss = v_loss\n","                self.best_epoch = epoch + 1\n","\n","            else:\n","\n","\n","                if self.count >= self.patience - 1:\n","                    lr = lr * self.factor\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n","                    self.count = 0\n","                    self.stop_count = self.stop_count + 1\n","                    self.count = 0\n","                    if v_loss < self.lowest_vloss:\n","                        self.lowest_vloss = v_loss\n","                else:\n","                    self.count = self.count + 1\n","\n","        else:\n","            monitor = 'val_loss'\n","            if epoch == 0:\n","                pimprov = 0.0\n","\n","            else:\n","                pimprov = (self.lowest_vloss - v_loss ) * 100 / self.lowest_vloss\n","\n","            if v_loss < self.lowest_vloss:\n","                self.lowest_vloss = v_loss\n","                self.best_weights = self.model.get_weights()\n","                self.count = 0\n","                self.stop_count = 0\n","                self.best_epoch = epoch + 1\n","\n","            else:\n","                if self.count >= self.patience - 1:\n","                    lr = lr * self.factor\n","                    self.stop_count = self.stop_count + 1\n","                    self.count = 0\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n","\n","                else:\n","                    self.count = self.count + 1\n","\n","                if acc > self.highest_tracc:\n","                    self.highest_tracc = acc\n","\n","        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n","        print(msg)\n","\n","        if self.stop_count > self.stop_patience - 1:\n","            msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n","            print(msg)\n","            self.model.stop_training = True\n","\n","        else:\n","            if self.ask_epoch != None and self.ask_permission != 0:\n","                if epoch + 1 >= self.ask_epoch:\n","                    msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n","                    print(msg)\n","\n","                    ans = input('')\n","                    if ans == 'H' or ans == 'h':\n","                        msg = f'training has been halted at epoch {epoch + 1} due to user input'\n","                        print(msg)\n","                        self.model.stop_training = True\n","\n","                    else:\n","                        try:\n","                            ans = int(ans)\n","                            self.ask_epoch += ans\n","                            msg = f' training will continue until epoch {str(self.ask_epoch)}'\n","                            print(msg)\n","                            msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration')\n","                            print(msg)\n","\n","                        except Exception:\n","                            print('Invalid')"],"metadata":{"id":"qMI51F2EzzPf","executionInfo":{"status":"ok","timestamp":1698941592979,"user_tz":-330,"elapsed":459,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def plot_training(hist):\n","    '''\n","    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n","    '''\n","\n","    # Define needed variables\n","    tr_acc = hist.history['accuracy']\n","    tr_loss = hist.history['loss']\n","    val_acc = hist.history['val_accuracy']\n","    val_loss = hist.history['val_loss']\n","    index_loss = np.argmin(val_loss)\n","    val_lowest = val_loss[index_loss]\n","    index_acc = np.argmax(val_acc)\n","    acc_highest = val_acc[index_acc]\n","    Epochs = [i+1 for i in range(len(tr_acc))]\n","    loss_label = f'best epoch= {str(index_loss + 1)}'\n","    acc_label = f'best epoch= {str(index_acc + 1)}'\n","\n","\n","    plt.figure(figsize= (20, 8))\n","    plt.style.use('fivethirtyeight')\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n","    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n","    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n","    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n","    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.tight_layout\n","    plt.show()"],"metadata":{"id":"bk8R_uy2z2Eg","executionInfo":{"status":"ok","timestamp":1698941603871,"user_tz":-330,"elapsed":415,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import matplotlib as plt"],"metadata":{"id":"4CiBBN7Xz4uH","executionInfo":{"status":"ok","timestamp":1698941614724,"user_tz":-330,"elapsed":596,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n","\t'''\n","\tThis function plot confusion matrix method from sklearn package.\n","\t'''\n","\n","\tplt.figure(figsize= (10, 10))\n","\tplt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n","\tplt.title(title)\n","\tplt.colorbar()\n","\n","\ttick_marks = np.arange(len(classes))\n","\tplt.xticks(tick_marks, classes, rotation= 45)\n","\tplt.yticks(tick_marks, classes)\n","\n","\tif normalize:\n","\t\tcm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n","\t\tprint('Normalized Confusion Matrix')\n","\n","\telse:\n","\t\tprint('Confusion Matrix, Without Normalization')\n","\n","\tprint(cm)\n","\n","\tthresh = cm.max() / 2.\n","\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","\t\tplt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n","\n","\tplt.tight_layout()\n","\tplt.ylabel('True Label')\n","\tplt.xlabel('Predicted Label')"],"metadata":{"id":"1ZYjjY1-z7WW","executionInfo":{"status":"ok","timestamp":1698941631202,"user_tz":-330,"elapsed":416,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/Colab Notebooks/dataset'\n","\n","# try:\n","#     # Get splitted data\n","#     train_df, valid_df, test_df = split_data(data_dir)\n","\n","#     # Get Generators\n","#     batch_size = 40\n","#     train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n","\n","# except:\n","#     print('Invalid Input')"],"metadata":{"id":"R1XmF_XVz_Z5","executionInfo":{"status":"ok","timestamp":1698941848523,"user_tz":-330,"elapsed":953,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["filepaths = []\n","labels = []\n","folds = os.listdir(data_dir)\n","for fold in folds:\n","    foldpath = os.path.join(data_dir, fold)\n","    filelist = os.listdir(foldpath)\n","    for file in filelist:\n","        fpath = os.path.join(foldpath, file)\n","        filepaths.append(fpath)\n","        labels.append(fold)"],"metadata":{"id":"W9Wv4aeb0CG4","executionInfo":{"status":"ok","timestamp":1698941852548,"user_tz":-330,"elapsed":470,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["Fseries = pd.Series(filepaths, name= 'filepaths')\n","Lseries = pd.Series(labels, name='labels')"],"metadata":{"id":"JsogjgV80E0A","executionInfo":{"status":"ok","timestamp":1698941865295,"user_tz":-330,"elapsed":516,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["df=pd.concat([Fseries, Lseries], axis= 1)"],"metadata":{"id":"_CiuiPtP04hV","executionInfo":{"status":"ok","timestamp":1698941876135,"user_tz":-330,"elapsed":593,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmsGZMHB07Kq","executionInfo":{"status":"ok","timestamp":1698941887419,"user_tz":-330,"elapsed":579,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"7143be9c-b55a-4654-82bf-da703c800cc4"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4214, 2)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["strat = df['labels']\n","train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n","\n","    # valid and test dataframe\n","strat = dummy_df['labels']\n","valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)"],"metadata":{"id":"nkHtte2d096-","executionInfo":{"status":"ok","timestamp":1698941899077,"user_tz":-330,"elapsed":413,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["batch_size = 40\n","train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huJ185da1Azh","executionInfo":{"status":"ok","timestamp":1698941910955,"user_tz":-330,"elapsed":1231,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"21fd16db-9efc-400e-ff64-08bd414a8f82"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3371 validated image filenames belonging to 4 classes.\n","Found 421 validated image filenames belonging to 4 classes.\n","Found 422 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["show_images(train_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"upT1Bf951Deh","executionInfo":{"status":"error","timestamp":1698941940655,"user_tz":-330,"elapsed":17514,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"5bf7d826-95ac-40f8-99e1-8b67a4788e1d"},"execution_count":23,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-66a66b804b03>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-00e8906972fb>\u001b[0m in \u001b[0;36mshow_images\u001b[0;34m(gen)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"]}]},{"cell_type":"code","source":["# Create Model Structure\n","img_size = (224, 224)\n","channels = 3\n","img_shape = (img_size[0], img_size[1], channels)\n","class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n","\n","# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n","# we will use efficientnetb3 from EfficientNet family.\n","base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","\n","model = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","\n","model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybqoFl7i1Gu6","executionInfo":{"status":"ok","timestamp":1698941993831,"user_tz":-330,"elapsed":9883,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"2e4cdbc6-d6d5-49b9-9635-1aa194fe0a12"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n","43941136/43941136 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetb3 (Functional  (None, 1536)              10783535  \n"," )                                                               \n","                                                                 \n"," batch_normalization (Batch  (None, 1536)              6144      \n"," Normalization)                                                  \n","                                                                 \n"," dense (Dense)               (None, 256)               393472    \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 1028      \n","                                                                 \n","=================================================================\n","Total params: 11184179 (42.66 MB)\n","Trainable params: 11093804 (42.32 MB)\n","Non-trainable params: 90375 (353.03 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 40   # set batch size for training\n","epochs = 40   # number of all epochs in training\n","patience = 1   #number of epochs to wait to adjust lr if monitored value does not improve\n","stop_patience = 3   # number of epochs to wait before stopping training if monitored value does not improve\n","threshold = 0.9   # if train accuracy is < threshold adjust monitor accuracy, else monitor validation loss\n","factor = 0.5   # factor to reduce lr by\n","ask_epoch = 5   # number of epochs to run before asking if you want to halt training\n","batches = int(np.ceil(len(train_gen.labels) / batch_size))    # number of training batch to run per epoch\n","\n","callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]"],"metadata":{"id":"ZiIFEEG11Vo1","executionInfo":{"status":"ok","timestamp":1698942015807,"user_tz":-330,"elapsed":618,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":[" history = model.fit(x= train_gen, epochs= epochs, verbose= 1, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iJCA2Mqk1dQq","executionInfo":{"status":"error","timestamp":1698944956194,"user_tz":-330,"elapsed":1022918,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"e8f87e84-dd57-40b5-ed46-6a0030d5dcb0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Do you want model asks you to halt the training [y/n] ?\n"," Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n","Epoch 1/40\n","85/85 [==============================] - ETA: 0s - loss: 7.3481 - accuracy: 0.7760 1 /40     7.348   77.603   6.29517  82.423   0.00100  0.00100  accuracy     0.00    764.83 \n","85/85 [==============================] - 765s 8s/step - loss: 7.3481 - accuracy: 0.7760 - val_loss: 6.2952 - val_accuracy: 0.8242\n","Epoch 2/40\n","85/85 [==============================] - ETA: 0s - loss: 5.1571 - accuracy: 0.9012 2 /40     5.157   90.122   4.58580  88.124   0.00100  0.00100  val_loss    27.15    57.66  \n","85/85 [==============================] - 58s 677ms/step - loss: 5.1571 - accuracy: 0.9012 - val_loss: 4.5858 - val_accuracy: 0.8812\n","Epoch 3/40\n","85/85 [==============================] - ETA: 0s - loss: 3.9003 - accuracy: 0.9255 3 /40     3.900   92.554   3.52015  89.311   0.00100  0.00100  val_loss    23.24    57.89  \n","85/85 [==============================] - 58s 679ms/step - loss: 3.9003 - accuracy: 0.9255 - val_loss: 3.5202 - val_accuracy: 0.8931\n","Epoch 4/40\n","85/85 [==============================] - ETA: 0s - loss: 3.0243 - accuracy: 0.9422 4 /40     3.024   94.215   2.64371  94.774   0.00100  0.00100  val_loss    24.90    57.15  \n","85/85 [==============================] - 57s 670ms/step - loss: 3.0243 - accuracy: 0.9422 - val_loss: 2.6437 - val_accuracy: 0.9477\n","Epoch 5/40\n","85/85 [==============================] - ETA: 0s - loss: 2.3500 - accuracy: 0.9594 5 /40     2.350   95.936   2.09684  94.299   0.00100  0.00100  val_loss    20.69    57.23  \n","enter H to halt training or an integer for number of epochs to run then ask again\n"," training will continue until epoch 15\n"," Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n","85/85 [==============================] - 62s 728ms/step - loss: 2.3500 - accuracy: 0.9594 - val_loss: 2.0968 - val_accuracy: 0.9430\n","Epoch 6/40\n","85/85 [==============================] - ETA: 0s - loss: 1.8399 - accuracy: 0.9683 6 /40     1.840   96.826   1.64368  96.200   0.00100  0.00100  val_loss    21.61    57.01  \n","85/85 [==============================] - 57s 671ms/step - loss: 1.8399 - accuracy: 0.9683 - val_loss: 1.6437 - val_accuracy: 0.9620\n","Epoch 7/40\n","85/85 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.9677 7 /40     1.478   96.767   1.39044  93.112   0.00100  0.00100  val_loss    15.41    57.50  \n","85/85 [==============================] - 58s 674ms/step - loss: 1.4783 - accuracy: 0.9677 - val_loss: 1.3904 - val_accuracy: 0.9311\n","Epoch 8/40\n","85/85 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.9786 8 /40     1.171   97.864   1.12577  94.774   0.00100  0.00100  val_loss    19.04    59.25  \n","85/85 [==============================] - 59s 695ms/step - loss: 1.1712 - accuracy: 0.9786 - val_loss: 1.1258 - val_accuracy: 0.9477\n","Epoch 9/40\n","85/85 [==============================] - ETA: 0s - loss: 0.9441 - accuracy: 0.9825 9 /40     0.944   98.250   0.91415  96.200   0.00100  0.00100  val_loss    18.80    57.40  \n","85/85 [==============================] - 58s 674ms/step - loss: 0.9441 - accuracy: 0.9825 - val_loss: 0.9141 - val_accuracy: 0.9620\n","Epoch 10/40\n","85/85 [==============================] - ETA: 0s - loss: 0.7535 - accuracy: 0.990810 /40     0.753   99.080   0.75236  96.200   0.00100  0.00100  val_loss    17.70    57.53  \n","85/85 [==============================] - 58s 675ms/step - loss: 0.7535 - accuracy: 0.9908 - val_loss: 0.7524 - val_accuracy: 0.9620\n","Epoch 11/40\n","85/85 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.986411 /40     0.627   98.635   0.68684  94.299   0.00100  0.00100  val_loss     8.71    57.19  \n","85/85 [==============================] - 57s 670ms/step - loss: 0.6270 - accuracy: 0.9864 - val_loss: 0.6868 - val_accuracy: 0.9430\n","Epoch 12/40\n","85/85 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.989312 /40     0.522   98.932   0.57214  95.249   0.00100  0.00100  val_loss    16.70    56.91  \n","85/85 [==============================] - 57s 667ms/step - loss: 0.5216 - accuracy: 0.9893 - val_loss: 0.5721 - val_accuracy: 0.9525\n","Epoch 13/40\n","85/85 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.995313 /40     0.426   99.525   0.49956  94.774   0.00100  0.00100  val_loss    12.69    57.68  \n","85/85 [==============================] - 58s 677ms/step - loss: 0.4258 - accuracy: 0.9953 - val_loss: 0.4996 - val_accuracy: 0.9477\n","Epoch 14/40\n","85/85 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.993814 /40     0.362   99.377   0.47274  95.012   0.00100  0.00100  val_loss     5.37    57.36  \n","85/85 [==============================] - 58s 671ms/step - loss: 0.3616 - accuracy: 0.9938 - val_loss: 0.4727 - val_accuracy: 0.9501\n","Epoch 15/40\n","85/85 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.992915 /40     0.316   99.288   0.43258  95.012   0.00100  0.00100  val_loss     8.50    57.73  \n","enter H to halt training or an integer for number of epochs to run then ask again\n","10\n"," training will continue until epoch 25\n"," Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n","85/85 [==============================] - 572s 7s/step - loss: 0.3158 - accuracy: 0.9929 - val_loss: 0.4326 - val_accuracy: 0.9501\n","Epoch 16/40\n","85/85 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.991716 /40     0.286   99.169   0.38377  94.537   0.00100  0.00100  val_loss    11.28    56.66  \n","85/85 [==============================] - 57s 662ms/step - loss: 0.2859 - accuracy: 0.9917 - val_loss: 0.3838 - val_accuracy: 0.9454\n","Epoch 17/40\n","85/85 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.992617 /40     0.254   99.258   0.33016  95.962   0.00100  0.00100  val_loss    13.97    56.48  \n","85/85 [==============================] - 57s 664ms/step - loss: 0.2545 - accuracy: 0.9926 - val_loss: 0.3302 - val_accuracy: 0.9596\n","Epoch 18/40\n","85/85 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.988118 /40     0.246   98.813   0.33548  95.724   0.00100  0.00050  val_loss    -1.61    59.19  \n","85/85 [==============================] - 59s 694ms/step - loss: 0.2463 - accuracy: 0.9881 - val_loss: 0.3355 - val_accuracy: 0.9572\n","Epoch 19/40\n","85/85 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.996719 /40     0.210   99.674   0.30901  96.437   0.00050  0.00050  val_loss     6.41    57.56  \n","85/85 [==============================] - 58s 675ms/step - loss: 0.2096 - accuracy: 0.9967 - val_loss: 0.3090 - val_accuracy: 0.9644\n","Epoch 20/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.997620 /40     0.196   99.763   0.31198  95.962   0.00050  0.00025  val_loss    -0.96    57.23  \n","85/85 [==============================] - 57s 670ms/step - loss: 0.1961 - accuracy: 0.9976 - val_loss: 0.3120 - val_accuracy: 0.9596\n","Epoch 21/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.997921 /40     0.187   99.792   0.31212  95.487   0.00025  0.00013  val_loss    -1.01    57.27  \n","85/85 [==============================] - 57s 669ms/step - loss: 0.1869 - accuracy: 0.9979 - val_loss: 0.3121 - val_accuracy: 0.9549\n","Epoch 22/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.998822 /40     0.180   99.881   0.30509  95.249   0.00013  0.00013  val_loss     1.27    56.68  \n","85/85 [==============================] - 57s 665ms/step - loss: 0.1803 - accuracy: 0.9988 - val_loss: 0.3051 - val_accuracy: 0.9525\n","Epoch 23/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.998523 /40     0.179   99.852   0.30124  95.249   0.00013  0.00013  val_loss     1.26    57.24  \n","85/85 [==============================] - 57s 668ms/step - loss: 0.1793 - accuracy: 0.9985 - val_loss: 0.3012 - val_accuracy: 0.9525\n","Epoch 24/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.998524 /40     0.176   99.852   0.29849  95.962   0.00013  0.00013  val_loss     0.91    56.93  \n","85/85 [==============================] - 57s 669ms/step - loss: 0.1762 - accuracy: 0.9985 - val_loss: 0.2985 - val_accuracy: 0.9596\n","Epoch 25/40\n","85/85 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.997925 /40     0.176   99.792   0.30381  95.724   0.00013  0.00006  val_loss    -1.78    57.60  \n","enter H to halt training or an integer for number of epochs to run then ask again\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-d4e945a31c5c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x= train_gen, epochs= epochs, verbose= 1, callbacks= callbacks,\n\u001b[0m\u001b[1;32m      2\u001b[0m                    validation_data= valid_gen, validation_steps= None, shuffle= False)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-47f5d4ea84c0>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'H'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'training has been halted at epoch {epoch + 1} due to user input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":[" ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQFSNdj91gLd","executionInfo":{"status":"ok","timestamp":1698945096289,"user_tz":-330,"elapsed":127957,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"5ef7cd78-620e-44dd-f8c7-074e52716d94"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":[" 85/211 [===========>..................] - ETA: 59s - loss: 0.1511 - accuracy: 1.0000"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 211 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["211/211 [==============================] - 40s 190ms/step - loss: 0.1511 - accuracy: 1.0000\n"," 11/211 [>.............................] - ETA: 1:00 - loss: 0.3038 - accuracy: 0.9572"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 211 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["211/211 [==============================] - 3s 15ms/step - loss: 0.3038 - accuracy: 0.9572\n","211/211 [==============================] - 78s 367ms/step - loss: 0.3427 - accuracy: 0.9455\n","Train Loss:  0.15109173953533173\n","Train Accuracy:  1.0\n","--------------------\n","Validation Loss:  0.30381423234939575\n","Validation Accuracy:  0.9572446346282959\n","--------------------\n","Test Loss:  0.34270355105400085\n","Test Accuracy:  0.9454976320266724\n"]}]},{"cell_type":"code","source":["model_name = model.input_names[0][:-6]\n","subject = 'Eye Disease'\n","acc = test_score[1] * 100\n","save_path = ''\n","\n","# Save model\n","save_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\n","model_save_loc = os.path.join(save_path, save_id)\n","model.save(model_save_loc)\n","print(f'model was saved as {model_save_loc}')\n","\n","# Save weights\n","weight_save_id = str(f'{model_name}-{subject}-weights.h5')\n","weights_save_loc = os.path.join(save_path, weight_save_id)\n","model.save_weights(weights_save_loc)\n","print(f'weights were saved as {weights_save_loc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShC9-VLTBRxj","executionInfo":{"status":"ok","timestamp":1698945138054,"user_tz":-330,"elapsed":2154,"user":{"displayName":"Kethan Gudelli","userId":"00194759700163312926"}},"outputId":"07344060-95b1-4206-b057-bc44fd8a0ecd"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["model was saved as efficientnetb3-Eye Disease-94.55.h5\n","weights were saved as efficientnetb3-Eye Disease-weights.h5\n"]}]},{"cell_type":"code","source":["model.save()"],"metadata":{"id":"5Z6Z_CUyHU6V"},"execution_count":null,"outputs":[]}]}